function reach_ieee24_gnnv(model_folder, epsList)
% REACH_IEEE24_GNNV — Graph-level L_inf certification on IEEE24 with GNNV/NNV
% Model: 3 GCN layers -> global_max_pool -> linear head (2 logits)
%
% Inputs
%   model_folder : folder with
%       - ieee24_cascading_model_export.json
%       - ieee24_cascading_data_export.json
%   epsList      : vector of ε radii (e.g., [0 0.01 0.03])
%
% Outputs (per ε)
%   <model_folder>/results/ieee24_gnnv/graph_epsXXXX.mat  (saved -v7.3)
%     Rcell, labels, preds, isRobust, tGraph, eps

%% 0) Load model (3 GCN + max pool + linear head)
mdl    = jsondecode(fileread(fullfile(model_folder,'ieee24_cascading_model_export.json')));
layers = mdl.layers;

% Expect 4 layers total: 3 GCNs (1,2,3) + linear head (4)
W1 = double(layers(1).W); b1 = double(layers(1).b(:));  act1 = get_act(layers(1));
W2 = double(layers(2).W); b2 = double(layers(2).b(:));  act2 = get_act(layers(2));
W3 = double(layers(3).W); b3 = double(layers(3).b(:));  act3 = get_act(layers(3));
W_out = double(layers(4).W); b_out = double(layers(4).b(:));

%% 1) Load batched graph data
tbl  = neuralNetwork.readGNNdata(fullfile(model_folder,'ieee24_cascading_data_export.json'));

Xall = tbl.input{1};                 % N x 24 x 3 (nodes x feats per graph)
Ngraphs = size(Xall, 1);

% Python outputs (ensure N x 2)
Ypy = double(tbl.output{1});
if size(Ypy,2) ~= 2 && size(Ypy,1) == 2, Ypy = Ypy.'; end
assert(size(Ypy,2) == 2, 'Unexpected output shape; expected N×2.');

% Ground-truth labels (N×1 or N×2)
Traw = tbl.target_label{1};
if iscell(Traw), Traw = cell2mat(Traw); end
Traw = double(Traw);
if size(Traw,2) == 1
    y_true = 1 + (Traw(:) > 0.5);          % 0/1 -> 1/2
elseif size(Traw,2) == 2
    [~, y_true] = max(Traw, [], 2);        % one-hot -> 1/2
else
    error('Unexpected target_label shape: %s', mat2str(size(Traw)));
end
y_true = y_true(:);

% Python predictions from export
[~, py_pred] = max(Ypy, [], 2);

fprintf('Loaded %d graphs (batched: N x 24 x 3)\n', Ngraphs);
fprintf('Python-export preds: stable=%d (%.2f%%), unstable=%d (%.2f%%)\n', ...
    sum(py_pred==1), 100*mean(py_pred==1), sum(py_pred==2), 100*mean(py_pred==2));
fprintf('Ground truth:       stable=%d, unstable=%d\n\n', sum(y_true==1), sum(y_true==2));

%% 1.1 Edges — hardcode IEEE-24 undirected template (0-based)
use_dataset_edges = false;  % << hard-code topology for IEEE24 (set true to use JSON edge_index if present)

if use_dataset_edges && ismember('edge_index', tbl.Properties.VariableNames) && ~isempty(tbl.edge_index{1})
    Eall = tbl.edge_index{1};    % N x 2 x E (0-based)
    fprintf('Using edge_index from dataset JSON.\n');
else
    % Template: (2×E) 0-based undirected lines (one copy per line)
    E_template = ( ...
        [ 1,2; 1,3; 1,5; 2,4; 2,6; 3,9; 3,24; 4,9; 5,10; 6,10; ...
          7,8; 8,9; 8,10; 9,11; 9,12; 10,11; 10,12; 11,13; 11,14; ...
          12,13; 12,23; 13,23; 14,16; 15,16; 15,21; 15,24; 16,17; ...
          16,19; 17,18; 17,22; 18,21; 19,20; 20,23; 21,22; 22,24; 4,5; 6,7; 13,15 ]' - 1 ); % (2×E)
    fprintf('Using hardcoded IEEE24 topology: %d edges\n', size(E_template,2));
end

%% 2) Setup
relu   = ReluLayer();
method = 'approx-star';
outDir = fullfile(model_folder,'results','ieee24_gnnv');
if ~exist(outDir,'dir'), mkdir(outDir); end

%% 3) Loop over ε
for eps = epsList(:).'
    fprintf('=== IEEE24: ε = %.4f ===\n', eps);

    Rcell    = cell(Ngraphs,1);
    labels   = zeros(Ngraphs,1);
    preds    = zeros(Ngraphs,1);
    isRobust = zeros(Ngraphs,1);
    tGraph   = zeros(Ngraphs,1);

    for g = 1:Ngraphs
        t0 = tic;

        % Features (24×3)
        X_g = squeeze(Xall(g, :, :));       % nodes x feats
        n_nodes = size(X_g, 1);             % 24
        n_feat  = size(X_g, 2);             % 3
        labels(g) = y_true(g);

        % Edges (0-based -> build binary, undirected A with exactly one self-loop per node)
        if use_dataset_edges && exist('Eall','var')
            E_g = squeeze(Eall(g, :, :));   % 2×E, 0-based
        else
            E_g = E_template;               % 2×E, 0-based
        end
        A = sparse(E_g(1,:)+1, E_g(2,:)+1, 1, n_nodes, n_nodes);
        A = spones(A + A.');                                 % undirected union (binary)
        A = A - spdiags(diag(A), 0, n_nodes, n_nodes);       % clear any existing diagonal
        A = A + speye(n_nodes);                              % add exactly one self-loop per node

        % Symmetric GCN normalization: Â = D^{-1/2} A D^{-1/2}
        deg   = sum(A, 2);
        Dinv2 = spdiags(1./sqrt(max(deg,1)), 0, n_nodes, n_nodes);
        Ahat  = Dinv2 * A * Dinv2;

        % Input ImageStar: features×nodes center, one generator per node (L_inf by node)
        V = zeros(n_feat, n_nodes, 1, n_nodes+1);
        V(:,:,1,1) = X_g.';                                 % center: feats×nodes
        for p = 1:n_nodes
            V(:,p,1,p+1) = 1;                               % one generator per node
        end
        C = [eye(n_nodes); -eye(n_nodes)];                  % |δ_p| ≤ ε
        d = eps * ones(2*n_nodes,1);
        Xstar = ImageStar(V, C, d, -eps*ones(n_nodes,1), eps*ones(n_nodes,1));
       
        X0 = X_g.';                        % feats×nodes
        H1c = (W1 * X0) * Ahat + b1;       % linear -> aggregate -> bias
        if strcmp(act1,'relu'), H1c = max(H1c, 0); end
        
        H2c = (W2 * H1c) * Ahat + b2;
        if strcmp(act2,'relu'), H2c = max(H2c, 0); end
        
        H3c = (W3 * H2c) * Ahat + b3;      % last GCN (usually no ReLU if act3=="")
        
        hpool0 = max(H3c, [], 2);          % TRUE global max-pool on nominal features
        z0_nom = W_out * hpool0 + b_out;   % 2×1 logits at ε=0
        [~, preds(g)] = max(z0_nom);       % <-- use this for accuracy/match-rate
        
        % (Optional) debug print: use z0_nom here, not Y.V center
        if g <= 3 || (g >= 100 && g < 103)
            fprintf('[DBG g=%d, eps=%.4f] z0_nom=[%.4f, %.4f], pred=%d, lbl=%d\n', ...
                g, eps, z0_nom(1), z0_nom(2), preds(g), labels(g));
        end


        try
            % -------- Forward: 3×(GCN) with ReLU on first two only --------
            H1 = gconv_ieee24(Xstar, W1, b1, Ahat);         % linear -> aggregate -> bias
            if strcmp(act1,'relu'), H1 = relu.reach(H1, method); end

            H2 = gconv_ieee24(H1, W2, b2, Ahat);
            if strcmp(act2,'relu'), H2 = relu.reach(H2, method); end

            H3 = gconv_ieee24(H2, W3, b3, Ahat);
            % last GCN typically no activation in export (act3 == "")

            % -------- Global MAX pooling (sound over-approx via bounds) --------
            % Use ImageStar bounds directly (fast)
            [lb, ub] = H3.getRanges();                      % (n_hidden*n_nodes)×1
            n_hidden = size(W3,1);
            assert(numel(lb) == n_hidden*n_nodes, 'Range length mismatch for pooling.');
            lb = reshape(lb, [n_hidden, n_nodes]);
            ub = reshape(ub, [n_hidden, n_nodes]);
            lb_pool = max(lb, [], 2);                       % n_hidden×1
            ub_pool = max(ub, [], 2);                       % n_hidden×1

            % Box Star for pooled features
            H_pooled = Star(lb_pool, ub_pool);              % dim = n_hidden

            % -------- Final linear head --------
            Y = H_pooled.affineMap(W_out, b_out);           % 2 logits (Star or ImageStar)

            % Center prediction (ε=0 center)
            if isa(Y, 'ImageStar'), Yc = Y.toStar(); else, Yc = Y; end
            z0 = double(Yc.V(:,1));                         % center
            [~, preds(g)] = max(z0);

            % Verify spec (true logit ≥ other)
            Hs = label2Hs_binary(labels(g));
            vflag = verify_specification(Yc, Hs);
            isRobust(g) = double(vflag == 1);

            % Lightweight debug on a few graphs
            if g <= 3 || (g >= 100 && g < 103)
                fprintf('[DBG g=%d, eps=%.4f] z0=[%.4f, %.4f], pred=%d, lbl=%d, v=%d\n', ...
                    g, eps, z0(1), z0(2), preds(g), labels(g), vflag);
            end

        catch ME
            fprintf('⚠️  ERROR at graph %d: %s\n', g, ME.message);
            isRobust(g) = 0;
        end

        tGraph(g) = toc(t0);
        if mod(g, 100) == 0
            fprintf('  Processed %d / %d graphs\n', g, Ngraphs);
        end
    end

    % Save (v7.3 avoids 2GB limit). NOTE: Rcell can be huge; keep only if needed.
    fname = fullfile(outDir, sprintf('graph_eps%.4f.mat', eps));
    save(fname, 'Rcell','labels','preds','isRobust','tGraph','eps', '-v7.3');
    fprintf('✅  Saved: %s\n', fname);

    % Summary
    acc = mean(preds == labels) * 100;
    rob = mean(isRobust == 1) * 100;

    fprintf('\nMATLAB preds: stable=%d (%.2f%%), unstable=%d (%.2f%%)\n', ...
        sum(preds==1), 100*mean(preds==1), sum(preds==2), 100*mean(preds==2));

    fprintf('Python preds: stable=%d (%.2f%%), unstable=%d (%.2f%%)\n', ...
        sum(py_pred==1), 100*mean(py_pred==1), sum(py_pred==2), 100*mean(py_pred==2));

    match_rate = mean(preds(:) == py_pred(:)) * 100;
    fprintf('Match rate vs Python (all): %.2f%%\n', match_rate);

    if eps == 0
        tn = sum(preds==1 & labels==1); tp = sum(preds==2 & labels==2);
        fprintf('Per-class correct @ε=0: stable=%d/%d (%.2f%%), unstable=%d/%d (%.2f%%)\n', ...
            tn, sum(labels==1), 100*tn/max(1,sum(labels==1)), ...
            tp, sum(labels==2), 100*tp/max(1,sum(labels==2)));
    end

    fprintf('  Accuracy: %.2f%%  |  Verified: %.2f%%  |  Time: %.1fs\n\n', ...
        acc, rob, sum(tGraph));
end
end

%% -------- Helper: one GCN layer (linear -> aggregate -> bias) --------
function Z = gconv_ieee24(X, W, b, Ahat)
% X: ImageStar with data laid out as (features × nodes)
V = X.V; [~, n, ~, P] = size(V);
fout = size(W,1);
Vnew = zeros(fout, n, 1, P);
for q = 1:P
    H = squeeze(V(:,:,1,q));          % fin × n
    Hlin = W * H;                      % linear first (fout × n)
    Hagg = Hlin * Ahat;                % then aggregate (right-multiply by Â)
    Vnew(:,:,1,q) = Hagg + b;          % add bias (broadcast across columns)
end
Z = ImageStar(Vnew, X.C, X.d, X.pred_lb, X.pred_ub);
end

%% -------- Helper: activation tag --------
function a = get_act(L)
a = ""; 
if isfield(L,'act') && ~isempty(L.act), a = string(L.act); end
end

%% -------- Helper: spec half-space (true_logit ≥ other_logit) --------
function Hs = label2Hs_binary(lbl)
if lbl == 1          % stable: l1 - l2 ≥ 0
    Hs = HalfSpace([ 1 -1], 0);
else                  % unstable: l2 - l1 ≥ 0
    Hs = HalfSpace([-1  1], 0);
end
end



% function reach_ieee24_gnnv(model_folder, epsList)
% %% 0) Load model (3 GCN layers + global_mean_pool + linear head)
% mdl = jsondecode(fileread(fullfile(model_folder,'ieee24_cascading_model_export.json')));
% layers = mdl.layers;
% 
% % Extract GCN layers (assume layers 1,2 are GCN with W,b)
% W1 = double(layers(1).W); b1 = double(layers(1).b(:));
% W2 = double(layers(2).W); b2 = double(layers(2).b(:));
% W_out = double(layers(3).W); b_out = double(layers(3).b(:));
% 
% 
% %% 1) Load graph data
% tbl = neuralNetwork.readGNNdata(fullfile(model_folder,'ieee24_cascading_data_export.json'));
% 
% Ypy   = double(tbl.output{1});         % N×2 logits/probs from Python
% Traw  = tbl.target_label{1};           % N×1 or N×2
% N     = size(Ypy,1);
% 
% % Argmax predictions from Python’s outputs
% [~, py_pred] = max(Ypy, [], 2);        % 1=stable, 2=unstable
% 
% % Ground truth from target_label
% if size(Traw,2)==1
%     y_true = 1 + (double(Traw(:))>0.5);
% else
%     [~, y_true] = max(double(Traw), [], 2);
% end
% 
% acc = mean(py_pred==y_true);
% % Balanced accuracy = mean of per-class recalls
% rec1 = sum(py_pred==1 & y_true==1) / sum(y_true==1);
% rec2 = sum(py_pred==2 & y_true==2) / sum(y_true==2);
% bacc = (rec1 + rec2)/2;
% 
% fprintf('Python-export accuracy on the 2001 set: %.3f\n', acc);
% fprintf('Python-export balanced accuracy:        %.3f\n', bacc);
% 
% Ypy = tbl.output{1};         % expected shape N×2 (logits or probs)
% Lpy = tbl.output_label{1};   % expected shape N×1 (0/1) or N×2 (one-hot)
% 
% N = size(Ypy,1);
% if size(Lpy,2)==1
%     py_pred = 1 + (double(Lpy(:)) > 0.5);          % 1=stable,2=unstable
% elseif size(Lpy,2)==2
%     [~,py_pred] = max(double(Lpy),[],2);           % 1/2
% else
%     [~,py_pred] = max(double(Ypy),[],2);           % fallback: argmax on outputs
% end
% 
% Ngraphs = height(tbl);
% fprintf('Loaded %d graphs (24 nodes, 3 features each)\n', Ngraphs);
% 
% %% 2) Setup
% relu   = ReluLayer();
% method = 'approx-star';
% outDir = fullfile(model_folder,'results','ieee24_gnnv');
% if ~exist(outDir,'dir'), mkdir(outDir); end
% 
% %% 3) Loop over ε
% for eps = epsList(:).'
%     fprintf('\n=== IEEE24: ε = %.4f ===\n', eps);
% 
%     Rcell    = cell(Ngraphs,1);
%     labels   = zeros(Ngraphs,1);  % true labels (1-based)
%     preds    = zeros(Ngraphs,1);  % predictions at ε=0
%     isRobust = zeros(Ngraphs,1);
%     tGraph   = zeros(Ngraphs,1);
% 
% 
%     Xall = tbl.input{1};             % double, size N×24×3
%     Eall = tbl.edge_index{1};        % double, size N×2×E
%     Lall = tbl.target_label{1};      % numeric/logical (N×1 or N×2 or N×K)
%     Ngraphs = size(Xall, 1);
%     fprintf('Loaded %d graphs (batched: N x 24 x 3)\n', Ngraphs);
% 
%     % optional: guard rails
%     assert(size(Xall,2)==24 && size(Xall,3)==3,  'input must be N×24×3');
%     assert(size(Eall,2)==2,                      'edge_index must be N×2×E (0-based)');
% 
% 
%     for g = 1:Ngraphs
%         t0 = tic;
% 
%         % Get graph data
%         X_g = squeeze(Xall(g, :, :));           % 24×3
%         E_g = squeeze(Eall(g, :, :));      % 2×E (0-based)
%         lbl = parse_label_batched_row(Lall, g);   % helper below
%         labels(g) = lbl;
% 
%         n_nodes = size(X_g, 1);  % should be 24
%         n_feat  = size(X_g, 2);  % should be 3
% 
%         % Build normalized adjacency for this graph
%         A_g = sparse(E_g(1,:)+1, E_g(2,:)+1, 1, n_nodes, n_nodes);
%         if nnz(A_g - A_g.') ~= 0
%             A_g = A_g + A_g.';
%         end
%         if ~any(diag(A_g))   % no self-loops present
%             A_g = A_g + speye(n_nodes);
%         end
%         deg = sum(A_g, 2);
%         Dinv2 = spdiags(1./sqrt(deg), 0, n_nodes, n_nodes);
%         Ahat_g = Dinv2 * A_g * Dinv2;
% 
%         % Create ImageStar: perturb ALL nodes
%         % V: (n_feat × n_nodes × 1 × (n_nodes+1))
%         V = zeros(n_feat, n_nodes, 1, n_nodes+1);
%         V(:,:,1,1) = X_g';  % base: features as rows
%         for p = 1:n_nodes
%             V(:,p,1,p+1) = 1;  % one generator per node
%         end
%         C = [eye(n_nodes); -eye(n_nodes)];
%         d = eps*ones(2*n_nodes,1);
%         Xstar = ImageStar(V, C, d, -eps*ones(n_nodes,1), eps*ones(n_nodes,1));
% 
%         % Forward pass: 3 GCN layers + global_mean_pool + linear
%         try
%             H1 = relu.reach(gconv_ieee24(Xstar, W1, b1, Ahat_g), method);
%             H2 = gconv_ieee24(H1, W2, b2, Ahat_g);
% 
%             H2_star = H2.toStar();
%             n_hidden = size(W2,1); 
% 
%             V = H2_star.V;  % Shape: [n_hidden, n_nodes, n_basis]
%             n_basis = size(V, 3);
% 
%             H_pooled_V = zeros(n_hidden, 1, n_basis);
%             for b = 1:n_basis
%                 H_pooled_V(:, 1, b) = max(V(:, :, b), [], 2);  % Max across nodes
%             end
% 
%             H_pooled = Star(H_pooled_V, H2_star.C, H2_star.d);
% 
%             % Final linear layer: 2×32
%             Y = H_pooled.affineMap(W_out, b_out);
% 
%             % Get prediction at ε=0
%             logits_0 = Y.V(:,1,1,1);  % center
%             [~, pred_class] = max(logits_0);
%             preds(g) = pred_class;
% 
%             % Add debug output for first 5 graphs + a few around g=100
%             if g <= 5 || (g > 100 && g <= 105)
%                 fprintf('\n[DEBUG Graph %d, eps=%.4f, lbl=%d]\n', g, eps, lbl);
%                 fprintf('  Y type: %s\n', class(Y));
%                 fprintf('  Y.V size: %s\n', mat2str(size(Y.V)));
%                 fprintf('  logits_0: [%.4f, %.4f]\n', logits_0(1), logits_0(2));
%                 fprintf('  pred: %d (correct: %d)\n', pred_class, pred_class==lbl);
% 
%                 % Manual spec check
%                 if lbl == 1  % stable should have l1 > l2
%                     manual_holds = (logits_0(1) > logits_0(2));
%                 else
%                     manual_holds = (logits_0(2) > logits_0(1));
%                 end
%                 fprintf('  Manual spec check: %d\n', manual_holds);
%             end
% 
%             % Convert back to ImageStar format for storage
%             Rcell{g} = Y;
% 
%             % Get prediction at ε=0
%             logits_0 = Y.V(:,1,1,1);  % center
%             [~, pred_class] = max(logits_0);
%             preds(g) = pred_class;
% 
%             % Verify: true logit ≥ other logit
%             Hs = label2Hs_binary(lbl);
%             if isa(Y, 'ImageStar')
%                 Y_star = Y.toStar();
%             else
%                 Y_star = Y;
%             end
%             vflag = verify_specification(Y_star, Hs);
%             isRobust(g) = double(vflag == 1);
% 
%             if g <= 5 || (g > 100 && g <= 105)
%                 fprintf('  NNV verify result: %d\n', vflag);
% 
%                 % Check for mismatch
%                 if pred_class == lbl  % Only check if prediction is correct
%                     manual_holds = (lbl == 1 && logits_0(1) > logits_0(2)) || ...
%                                   (lbl == 2 && logits_0(2) > logits_0(1));
%                     if manual_holds && vflag ~= 1
%                         warning('⚠️  Graph %d: Should be verified but NNV says no!', g);
%                     elseif ~manual_holds && vflag == 1
%                         warning('⚠️  Graph %d: NNV verified but manual check fails!', g);
%                     end
%                 end
%             end
% 
%         catch ME
%             fprintf('⚠️  ERROR at graph %d: %s\n', g, ME.message);
%             isRobust(g) = 0;
%         end
% 
%         tGraph(g) = toc(t0);
% 
%         if mod(g, 100) == 0
%             fprintf('  Processed %d / %d graphs\n', g, Ngraphs);
%         end
%     end
% 
%     % Save results
%     fname = fullfile(outDir, sprintf('graph_eps%.4f.mat', eps));
%     save(fname, 'Rcell','labels','preds','isRobust','tGraph','eps');
%     fprintf('✅  Saved: %s\n', fname);
% 
%     % Quick summary
%     acc = mean(preds == labels) * 100;
%     rob = mean(isRobust) * 100;
% 
%     antisymW = norm(W_out(1,:) + W_out(2,:));
%     antisymB = abs(b_out(1) + b_out(2));
%     fprintf('Head antisymmetry: ||w1+w2||=%.3e, |b1+b2|=%.3e\n', antisymW, antisymB);
% 
%     fprintf('MATLAB preds: stable=%d (%.2f%%), unstable=%d (%.2f%%)\n', ...
%     sum(preds==1), 100*mean(preds==1), sum(preds==2), 100*mean(preds==2));
% 
%     fprintf('Python export preds: stable=%d (%.2f%%), unstable=%d (%.2f%%)\n', ...
%         sum(py_pred==1), 100*mean(py_pred==1), sum(py_pred==2), 100*mean(py_pred==2));
% 
%     % Python preds from JSON
%     Ypy = double(tbl.output{1});
%     [~, py_pred] = max(Ypy, [], 2);
% 
%     % MATLAB preds you compute in the loop
%     fprintf('Match rate vs Python (first 50): %.2f%%\n', ...
%             100*mean(preds(1:50) == py_pred(1:50)));
% 
%     fprintf('MATLAB preds: stable=%d (%.2f%%), unstable=%d (%.2f%%)\n', ...
%             sum(preds==1), 100*mean(preds==1), sum(preds==2), 100*mean(preds==2));
% 
% 
% 
%     fprintf('  Accuracy: %.2f%%  |  Verified: %.2f%%  |  Time: %.1fs\n', ...
%             acc, rob, sum(tGraph));
% end
% end
% 
% %% Helper functions
% 
% function Z = gconv_ieee24(X, W, b, Ahat)
% % Graph convolution: Z = ReLU(W @ (Ahat @ X) + b)
% % Follows PyTorch Geometric: transform THEN aggregate
% V = X.V;
% [~, n, ~, P] = size(V);
% fout = size(W,1);
% 
% Vnew = zeros(fout, n, 1, P);
% for q = 1:P
%     H = squeeze(V(:,:,1,q));           % fin × n
%     H_transformed = W * H;              % (fout × fin) * (fin × n) = fout × n
%     H_aggregated = H_transformed * Ahat';  % (fout × n) * (n × n) = fout × n
%     Vnew(:,:,1,q) = H_aggregated + b;   % Add bias
% end
% Z = ImageStar(Vnew, X.C, X.d, X.pred_lb, X.pred_ub);
% end
% 
% % function Ahat = normalizeAdjacency(A)
% % deg  = sum(A,2);
% % Dinv = spdiags(1./sqrt(deg), 0, size(A,1), size(A,1));
% % Ahat = Dinv * A * Dinv;
% % end
% 
% function Hs = label2Hs_binary(lbl)
% % Correct: enforce true_logit - other_logit >= 0
% if lbl == 1          % stable
%     Hs = HalfSpace([ 1 -1], 0);  % l1 - l2 >= 0
% else                  % unstable
%     Hs = HalfSpace([-1  1], 0);  % l2 - l1 >= 0
% end
% end
% 
% 
% function lbl = parse_label_batched_row(Lall, k)
%     % Accepts N×1, N×2, or N×K numeric/logical arrays
%     if iscell(Lall), Lall = Lall{1}; end
%     assert(size(Lall,1) >= k, 'Label batch too small');
% 
%     if size(Lall,2) == 1
%         v = double(Lall(k,1));
%         lbl = 1 + (v > 0.5);                 % 0/1 -> 1/2
%     elseif size(Lall,2) == 2
%         r = double(Lall(k,:));
%         [~, lbl] = max(r(:));                % argmax → 1/2
%     else
%         r = double(Lall(k,:));
%         lbl = 1 + double(any(r > 0.5));      % any indicator → unstable
%     end
% end
% 
